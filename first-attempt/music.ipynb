{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "music.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd5IDV81QFe8"
      },
      "source": [
        "#library for understanding music\n",
        "from music21 import *"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y2hEB0wQZV7"
      },
      "source": [
        "#defining function to read MIDI files\n",
        "def read_midi(file):\n",
        "    \n",
        "    print(\"Loading Music File:\",file)\n",
        "    \n",
        "    notes=[]\n",
        "    notes_to_parse = None\n",
        "    \n",
        "    #parsing a midi file\n",
        "    midi = converter.parse(file)\n",
        "  \n",
        "    #grouping based on different instruments\n",
        "    s2 = instrument.partitionByInstrument(midi)\n",
        "\n",
        "    #Looping over all the instruments\n",
        "    for part in s2.parts:\n",
        "    \n",
        "        #select elements of only piano\n",
        "        if 'Piano' in str(part): \n",
        "        \n",
        "            notes_to_parse = part.recurse() \n",
        "      \n",
        "            #finding whether a particular element is note or a chord\n",
        "            for element in notes_to_parse:\n",
        "                \n",
        "                #note\n",
        "                if isinstance(element, note.Note):\n",
        "                    notes.append(str(element.pitch))\n",
        "                \n",
        "                #chord\n",
        "                elif isinstance(element, chord.Chord):\n",
        "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    return np.array(notes)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI7uKmVWQ9is",
        "outputId": "0d855224-eb24-45e3-8ba0-05bdf474a9ff"
      },
      "source": [
        "#for listing down the file names\n",
        "import os\n",
        "\n",
        "#Array Processing\n",
        "import numpy as np\n",
        "\n",
        "#specify the path\n",
        "path='music_data/'\n",
        "\n",
        "#read all the filenames\n",
        "files=[i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
        "\n",
        "#reading each midi file\n",
        "notes_array = np.array([read_midi(path+i) for i in files])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Music File: music_data/schuim-3.mid\n",
            "Loading Music File: music_data/schubert_D935_4.mid\n",
            "Loading Music File: music_data/schumm-2.mid\n",
            "Loading Music File: music_data/schub_d960_1.mid\n",
            "Loading Music File: music_data/schuim-1.mid\n",
            "Loading Music File: music_data/schubert_D935_1.mid\n",
            "Loading Music File: music_data/schuim-4.mid\n",
            "Loading Music File: music_data/schubert_D850_1.mid\n",
            "Loading Music File: music_data/schub_d960_2.mid\n",
            "Loading Music File: music_data/schumm-3.mid\n",
            "Loading Music File: music_data/schumm-6.mid\n",
            "Loading Music File: music_data/schu_143_2.mid\n",
            "Loading Music File: music_data/schuim-2.mid\n",
            "Loading Music File: music_data/schubert_D935_2.mid\n",
            "Loading Music File: music_data/schub_d960_4.mid\n",
            "Loading Music File: music_data/schumm-4.mid\n",
            "Loading Music File: music_data/schub_d760_4.mid\n",
            "Loading Music File: music_data/schub_d960_3.mid\n",
            "Loading Music File: music_data/schubert_D850_2.mid\n",
            "Loading Music File: music_data/schumm-1.mid\n",
            "Loading Music File: music_data/schu_143_3.mid\n",
            "Loading Music File: music_data/schubert_D850_3.mid\n",
            "Loading Music File: music_data/schub_d760_1.mid\n",
            "Loading Music File: music_data/schumm-5.mid\n",
            "Loading Music File: music_data/schubert_D935_3.mid\n",
            "Loading Music File: music_data/schub_d760_3.mid\n",
            "Loading Music File: music_data/schu_143_1.mid\n",
            "Loading Music File: music_data/schub_d760_2.mid\n",
            "Loading Music File: music_data/schubert_D850_4.mid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1HbMHFmRORa",
        "outputId": "9c5f76fe-e41f-4809-834c-73e566c47cf8"
      },
      "source": [
        "#converting 2D array into 1D array\n",
        "notes_ = [element for note_ in notes_array for element in note_]\n",
        "\n",
        "#No. of unique notes\n",
        "unique_notes = list(set(notes_))\n",
        "print(len(unique_notes))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "IZJPvwkMTcvH",
        "outputId": "c80f12ce-1159-4976-8d06-6288991c5e7c"
      },
      "source": [
        "#importing library\n",
        "from collections import Counter\n",
        "\n",
        "#computing frequency of each note\n",
        "freq = dict(Counter(notes_))\n",
        "\n",
        "#library for visualiation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#consider only the frequencies\n",
        "no=[count for _,count in freq.items()]\n",
        "\n",
        "#set the figure size\n",
        "plt.figure(figsize=(5,5))\n",
        "\n",
        "#plot\n",
        "plt.hist(no)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([187.,  41.,  26.,  11.,   6.,   9.,  12.,   6.,   3.,   3.]),\n",
              " array([1.0000e+00, 1.4790e+02, 2.9480e+02, 4.4170e+02, 5.8860e+02,\n",
              "        7.3550e+02, 8.8240e+02, 1.0293e+03, 1.1762e+03, 1.3231e+03,\n",
              "        1.4700e+03]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 319,
              "height": 302
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF9WIUYlTwyG"
      },
      "source": [
        "From the above plot, we can infer that most of the notes have a very low frequency. So, let us keep the top frequent notes and ignore the low-frequency ones. Here, I am defining the threshold as 50. Nevertheless, the parameter can be changed.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "422RKNWXTtxH",
        "outputId": "3d2811d5-24b5-46c7-8331-530a43530e08"
      },
      "source": [
        "frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
        "print(len(frequent_notes))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHfSoSCOT9fo"
      },
      "source": [
        "new_music=[]\n",
        "\n",
        "for notes in notes_array:\n",
        "    temp=[]\n",
        "    for note_ in notes:\n",
        "        if note_ in frequent_notes:\n",
        "            temp.append(note_)            \n",
        "    new_music.append(temp)\n",
        "    \n",
        "new_music = np.array(new_music)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPjF9hZfUMYf",
        "outputId": "c9977124-7ebf-42c5-ec62-2b8ad8b8cde6"
      },
      "source": [
        "print(len(new_music))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seWGSYepUQl7"
      },
      "source": [
        "no_of_timesteps = 32\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for note_ in new_music:\n",
        "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
        "        \n",
        "        #preparing input and output sequences\n",
        "        input_ = note_[i:i + no_of_timesteps]\n",
        "        output = note_[i + no_of_timesteps]\n",
        "        \n",
        "        x.append(input_)\n",
        "        y.append(output)\n",
        "        \n",
        "x=np.array(x)\n",
        "y=np.array(y)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSL0xlmlUbXW"
      },
      "source": [
        "unique_x = list(set(x.ravel()))\n",
        "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmuXOSRSUfhM"
      },
      "source": [
        "#preparing input sequences\n",
        "x_seq=[]\n",
        "for i in x:\n",
        "    temp=[]\n",
        "    for j in i:\n",
        "        #assigning unique integer to every note\n",
        "        temp.append(x_note_to_int[j])\n",
        "    x_seq.append(temp)\n",
        "    \n",
        "x_seq = np.array(x_seq)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRjtoB1UUuGi"
      },
      "source": [
        "unique_y = list(set(y))\n",
        "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
        "y_seq=np.array([y_note_to_int[i] for i in y])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btBGTz9sUxIk"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCkQfvdeUzmd"
      },
      "source": [
        "def lstm():\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(128,return_sequences=True))\n",
        "  model.add(LSTM(128))\n",
        "  model.add(Dense(256))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(n_vocab))\n",
        "  model.add(Activation('softmax'))\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "  return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqbkACbygv6t",
        "outputId": "1b931d75-ed6d-41c8-9208-abc99b469a6a"
      },
      "source": [
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.callbacks import *\n",
        "import keras.backend as K\n",
        "\n",
        "K.clear_session()\n",
        "model = Sequential()\n",
        "    \n",
        "#embedding layer\n",
        "model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True)) \n",
        "\n",
        "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool1D(2))\n",
        "    \n",
        "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool1D(2))\n",
        "\n",
        "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool1D(2))\n",
        "          \n",
        "#model.add(Conv1D(256,5,activation='relu'))    \n",
        "model.add(GlobalMaxPool1D())\n",
        "    \n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(len(unique_y), activation='softmax'))\n",
        "    \n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 32, 100)           16700     \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 32, 64)            19264     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32, 64)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 16, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 16, 128)           24704     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 8, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 8, 256)            98560     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 256)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 4, 256)            0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 167)               42919     \n",
            "=================================================================\n",
            "Total params: 267,939\n",
            "Trainable params: 267,939\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYkf0mRxhKs5"
      },
      "source": [
        "mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-4XCa_Ii3uc",
        "outputId": "c1168ee4-2b7c-4883-d3e6-d35a2bfb6cd3"
      },
      "source": [
        "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 4.3442\n",
            "Epoch 00001: val_loss improved from inf to 4.02592, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 4.3434 - val_loss: 4.0259\n",
            "Epoch 2/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 3.7856\n",
            "Epoch 00002: val_loss improved from 4.02592 to 3.78760, saving model to best_model.h5\n",
            "403/403 [==============================] - 26s 65ms/step - loss: 3.7851 - val_loss: 3.7876\n",
            "Epoch 3/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 3.6033\n",
            "Epoch 00003: val_loss improved from 3.78760 to 3.65381, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 3.6028 - val_loss: 3.6538\n",
            "Epoch 4/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 3.4676\n",
            "Epoch 00004: val_loss improved from 3.65381 to 3.54659, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 3.4678 - val_loss: 3.5466\n",
            "Epoch 5/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 3.3597\n",
            "Epoch 00005: val_loss improved from 3.54659 to 3.49225, saving model to best_model.h5\n",
            "403/403 [==============================] - 28s 68ms/step - loss: 3.3599 - val_loss: 3.4922\n",
            "Epoch 6/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 3.2827\n",
            "Epoch 00006: val_loss improved from 3.49225 to 3.41816, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 3.2826 - val_loss: 3.4182\n",
            "Epoch 7/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 3.2032\n",
            "Epoch 00007: val_loss improved from 3.41816 to 3.33997, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 3.2033 - val_loss: 3.3400\n",
            "Epoch 8/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 3.1450\n",
            "Epoch 00008: val_loss improved from 3.33997 to 3.32337, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 66ms/step - loss: 3.1450 - val_loss: 3.3234\n",
            "Epoch 9/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 3.0880\n",
            "Epoch 00009: val_loss improved from 3.32337 to 3.28491, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 66ms/step - loss: 3.0881 - val_loss: 3.2849\n",
            "Epoch 10/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 3.0340\n",
            "Epoch 00010: val_loss improved from 3.28491 to 3.24154, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 66ms/step - loss: 3.0344 - val_loss: 3.2415\n",
            "Epoch 11/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.9863\n",
            "Epoch 00011: val_loss improved from 3.24154 to 3.20273, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.9863 - val_loss: 3.2027\n",
            "Epoch 12/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.9482\n",
            "Epoch 00012: val_loss improved from 3.20273 to 3.16387, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.9480 - val_loss: 3.1639\n",
            "Epoch 13/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.9020\n",
            "Epoch 00013: val_loss improved from 3.16387 to 3.12948, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.9024 - val_loss: 3.1295\n",
            "Epoch 14/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.8662\n",
            "Epoch 00014: val_loss improved from 3.12948 to 3.12231, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.8665 - val_loss: 3.1223\n",
            "Epoch 15/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.8352\n",
            "Epoch 00015: val_loss improved from 3.12231 to 3.07967, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 68ms/step - loss: 2.8353 - val_loss: 3.0797\n",
            "Epoch 16/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.7976\n",
            "Epoch 00016: val_loss improved from 3.07967 to 3.06816, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.7979 - val_loss: 3.0682\n",
            "Epoch 17/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.7654\n",
            "Epoch 00017: val_loss improved from 3.06816 to 3.04085, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 68ms/step - loss: 2.7657 - val_loss: 3.0408\n",
            "Epoch 18/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.7422\n",
            "Epoch 00018: val_loss did not improve from 3.04085\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.7420 - val_loss: 3.0437\n",
            "Epoch 19/50\n",
            "403/403 [==============================] - ETA: 0s - loss: 2.7145\n",
            "Epoch 00019: val_loss improved from 3.04085 to 3.02627, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.7145 - val_loss: 3.0263\n",
            "Epoch 20/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.6919\n",
            "Epoch 00020: val_loss improved from 3.02627 to 2.99639, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.6916 - val_loss: 2.9964\n",
            "Epoch 21/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.6680\n",
            "Epoch 00021: val_loss improved from 2.99639 to 2.99583, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 68ms/step - loss: 2.6682 - val_loss: 2.9958\n",
            "Epoch 22/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.6432\n",
            "Epoch 00022: val_loss improved from 2.99583 to 2.96076, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.6432 - val_loss: 2.9608\n",
            "Epoch 23/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.6229\n",
            "Epoch 00023: val_loss improved from 2.96076 to 2.94927, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 66ms/step - loss: 2.6229 - val_loss: 2.9493\n",
            "Epoch 24/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.6064\n",
            "Epoch 00024: val_loss improved from 2.94927 to 2.93662, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.6064 - val_loss: 2.9366\n",
            "Epoch 25/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.5894\n",
            "Epoch 00025: val_loss improved from 2.93662 to 2.93225, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.5894 - val_loss: 2.9323\n",
            "Epoch 26/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.5695\n",
            "Epoch 00026: val_loss improved from 2.93225 to 2.90195, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.5695 - val_loss: 2.9020\n",
            "Epoch 27/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.5529\n",
            "Epoch 00027: val_loss improved from 2.90195 to 2.89964, saving model to best_model.h5\n",
            "403/403 [==============================] - 26s 65ms/step - loss: 2.5529 - val_loss: 2.8996\n",
            "Epoch 28/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.5390\n",
            "Epoch 00028: val_loss did not improve from 2.89964\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.5393 - val_loss: 2.9052\n",
            "Epoch 29/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.5195\n",
            "Epoch 00029: val_loss improved from 2.89964 to 2.87820, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.5197 - val_loss: 2.8782\n",
            "Epoch 30/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.5157\n",
            "Epoch 00030: val_loss improved from 2.87820 to 2.86887, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.5157 - val_loss: 2.8689\n",
            "Epoch 31/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.4976\n",
            "Epoch 00031: val_loss improved from 2.86887 to 2.86376, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.4979 - val_loss: 2.8638\n",
            "Epoch 32/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.4890\n",
            "Epoch 00032: val_loss improved from 2.86376 to 2.84289, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 68ms/step - loss: 2.4886 - val_loss: 2.8429\n",
            "Epoch 33/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.4689\n",
            "Epoch 00033: val_loss did not improve from 2.84289\n",
            "403/403 [==============================] - 27s 66ms/step - loss: 2.4690 - val_loss: 2.8447\n",
            "Epoch 34/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.4571\n",
            "Epoch 00034: val_loss improved from 2.84289 to 2.84268, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.4571 - val_loss: 2.8427\n",
            "Epoch 35/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.4471\n",
            "Epoch 00035: val_loss did not improve from 2.84268\n",
            "403/403 [==============================] - 27s 68ms/step - loss: 2.4472 - val_loss: 2.8486\n",
            "Epoch 36/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.4358\n",
            "Epoch 00036: val_loss improved from 2.84268 to 2.83642, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.4360 - val_loss: 2.8364\n",
            "Epoch 37/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.4303\n",
            "Epoch 00037: val_loss improved from 2.83642 to 2.83441, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.4304 - val_loss: 2.8344\n",
            "Epoch 38/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.4121\n",
            "Epoch 00038: val_loss improved from 2.83441 to 2.81219, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 68ms/step - loss: 2.4122 - val_loss: 2.8122\n",
            "Epoch 39/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.4082\n",
            "Epoch 00039: val_loss improved from 2.81219 to 2.79724, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 68ms/step - loss: 2.4084 - val_loss: 2.7972\n",
            "Epoch 40/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.4040\n",
            "Epoch 00040: val_loss did not improve from 2.79724\n",
            "403/403 [==============================] - 28s 69ms/step - loss: 2.4038 - val_loss: 2.8071\n",
            "Epoch 41/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.3906\n",
            "Epoch 00041: val_loss improved from 2.79724 to 2.79211, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 66ms/step - loss: 2.3909 - val_loss: 2.7921\n",
            "Epoch 42/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.3813\n",
            "Epoch 00042: val_loss did not improve from 2.79211\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.3814 - val_loss: 2.7969\n",
            "Epoch 43/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.3749\n",
            "Epoch 00043: val_loss did not improve from 2.79211\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.3752 - val_loss: 2.8022\n",
            "Epoch 44/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.3657\n",
            "Epoch 00044: val_loss improved from 2.79211 to 2.77776, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 68ms/step - loss: 2.3663 - val_loss: 2.7778\n",
            "Epoch 45/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.3605\n",
            "Epoch 00045: val_loss did not improve from 2.77776\n",
            "403/403 [==============================] - 27s 68ms/step - loss: 2.3608 - val_loss: 2.7886\n",
            "Epoch 46/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.3562\n",
            "Epoch 00046: val_loss improved from 2.77776 to 2.77678, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.3563 - val_loss: 2.7768\n",
            "Epoch 47/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.3428\n",
            "Epoch 00047: val_loss improved from 2.77678 to 2.76377, saving model to best_model.h5\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.3427 - val_loss: 2.7638\n",
            "Epoch 48/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.3418\n",
            "Epoch 00048: val_loss did not improve from 2.76377\n",
            "403/403 [==============================] - 27s 68ms/step - loss: 2.3421 - val_loss: 2.7695\n",
            "Epoch 49/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.3337\n",
            "Epoch 00049: val_loss did not improve from 2.76377\n",
            "403/403 [==============================] - 27s 68ms/step - loss: 2.3334 - val_loss: 2.7676\n",
            "Epoch 50/50\n",
            "402/403 [============================>.] - ETA: 0s - loss: 2.3251\n",
            "Epoch 00050: val_loss did not improve from 2.76377\n",
            "403/403 [==============================] - 27s 67ms/step - loss: 2.3251 - val_loss: 2.7700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvLikSwli7Hj"
      },
      "source": [
        "#loading best model\n",
        "from keras.models import load_model\n",
        "model = load_model('best_model.h5')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4RL0VthoJa6",
        "outputId": "1e2b704b-71e2-4fa5-fa16-984c2abcf687"
      },
      "source": [
        "import random\n",
        "ind = np.random.randint(0,len(x_val)-1)\n",
        "\n",
        "random_music = x_val[ind]\n",
        "\n",
        "predictions=[]\n",
        "for i in range(10):\n",
        "\n",
        "    random_music = random_music.reshape(1,no_of_timesteps)\n",
        "\n",
        "    prob  = model.predict(random_music)[0]\n",
        "    y_pred= np.argmax(prob,axis=0)\n",
        "    predictions.append(y_pred)\n",
        "\n",
        "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
        "    random_music = random_music[1:]\n",
        "    \n",
        "print(predictions)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[99, 15, 15, 118, 118, 118, 118, 118, 118, 118]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgC3gDY-oNfY"
      },
      "source": [
        "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
        "predicted_notes = [x_int_to_note[i] for i in predictions]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irhWen-WoRqu",
        "outputId": "c42750b0-9d11-48c0-c494-e7895a2c5f66"
      },
      "source": [
        "print(predicted_notes)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['7.10.2', 'B-3', 'B-3', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YpnVvh_oVWR"
      },
      "source": [
        "def convert_to_midi(prediction_output):\n",
        "   \n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "        \n",
        "        # pattern is a chord\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                \n",
        "                cn=int(current_note)\n",
        "                new_note = note.Note(cn)\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "                \n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "            \n",
        "        # pattern is a note\n",
        "        else:\n",
        "            \n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 1\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "    midi_stream.write('midi', fp='music.mid')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zl0SsNSoaTu"
      },
      "source": [
        "convert_to_midi(predicted_notes)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1wNIWHWogQp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}